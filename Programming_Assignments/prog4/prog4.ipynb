{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUfJXYK6N3sc"
      },
      "source": [
        "## Introduction\n",
        "---\n",
        "\n",
        "In this programming assignment, we will train a neural net for caption generation.\n",
        "This neural network is made of two components: a feed forward convolutional net (CNN) --- to extract features from the images --- and a recurrent neural net (RNN) --- to output a variable length caption for each input image.\n",
        "We will use MNIST (handwritten digits) dataset for this purpose.\n",
        "\n",
        "## Instructions\n",
        "---\n",
        "\n",
        "You should perform this assignment using Google Colab.\n",
        "* Go through the notebook and ensure that you have answered all questions.\n",
        "* Finally, submit the ipynb `File > Download > Download .ipynb` on Brightspace\n",
        "\n",
        "---\n",
        "This code snippet imports necessary libraries for working with numerical and\n",
        "image data, defines the device for computation (either GPU or CPU), and sets up tools for building and training neural networks using PyTorch, a popular deep learning framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "sPhXVnjeGT2q"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional; nn.f = functional\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, transforms\n",
        "import string\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Use this constant to decide on which device to run the training - On Colab 'cuda:0' and 'cpu' refers to GPU and CPU respectively\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM7uKdhwRhhe"
      },
      "source": [
        "## Data loading\n",
        "---\n",
        "\n",
        "This code snippet sets up data pre-processing and creates data loaders for training and testing using the MNIST data set, which is commonly used for hand-written digit classification tasks in machine learning.\n",
        "\n",
        "`DataLoader`s abstract outs the loading of a data set and iterating batches of the loaded data set. You can read the documentation to learn more about `DataLoader`s and `Dataset`s [`DataLoader`s and `Dataset`s](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "TfTRYSNqJwq4"
      },
      "outputs": [],
      "source": [
        "# Batch options\n",
        "batch_size = 128  # input batch size for training\n",
        "test_batch = 1    # test batch size\n",
        "\n",
        "# Normalizes the input images for a better training\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "# Get train and test loaders to load MNIST data\n",
        "trainset = datasets.MNIST(root='.', train=True, download=True, transform=data_transform)\n",
        "testset = datasets.MNIST(root='.', train=False, download=True, transform=data_transform)\n",
        "\n",
        "# Create the dataloaders on which we can iterate to get the data in batch_size chunks\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader  = torch.utils.data.DataLoader(testset, batch_size=test_batch, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfyOh8yrQpXr"
      },
      "source": [
        "# 1 Preprocessing\n",
        "## 1.1 Auxiliary data creation\n",
        "---\n",
        "First, let's setup `labelDict` and `vocab` for our problem statement. For this,\n",
        "1. MNIST data set, consists of images and their corresponding labels of the form `{0, 1, 2, ‚Ä¶}`.\n",
        "First let's build a dictionary mapping labels to `<b>` $\\phi$ `<e>`, where $\\phi \\in \\lbrace \\texttt{zero}, \\texttt{one}, \\texttt{two}, \\ldots , \\texttt{nine}\\rbrace$.\n",
        "\n",
        "2. Build a lookup table for each unique tokens in the strings. Your `vocab` list, before sorting, should look like: `['<b>', 'z', 'e', 'r', 'o', '<e>', ‚Ä¶]`.\n",
        "\n",
        "Next, complete the following two functions:\n",
        "1.   `label_to_onehot_sequence()` to convert a label to its one-hot sequence, representing the sequence of tokens. You may want to look at [`functional.one_hot` documentation](https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html) for reference.\n",
        "2. and `token_idx_to_token()` to convert the list of token indices to their corresponding string of characters.\n",
        "\n",
        "The functions below are heavily annotated so that you understand what each function is doing and how can you use them for your use case.\n",
        "The `assert` is a simple way for testing the correctness of your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "QPOJLA7ommbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c9536b-2fb7-4acb-8ba7-9170d5573c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Vocabulary: ['<b>', '<e>', 'e', 'f', 'g', 'h', 'i', 'n', 'o', 'r', 's', 't', 'u', 'v', 'w', 'x', 'z']\n",
            "Vocabulary Size: 17\n"
          ]
        }
      ],
      "source": [
        "# Create dictionary and Lookup Table ###########################################\n",
        "# TODOüìù: labelDict = dictionary of sequences of tokens such that it converts\n",
        "#       label to digit into strings.\n",
        "# TODOüìù: vocab = list of all the unique tokens in labelDict.\n",
        "################################################################################\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "labelDict = {\n",
        "    0: '<b>zero<e>',\n",
        "    1: '<b>one<e>',\n",
        "    2: '<b>two<e>',\n",
        "    3: '<b>three<e>',\n",
        "    4: '<b>four<e>',\n",
        "    5: '<b>five<e>',\n",
        "    6: '<b>six<e>',\n",
        "    7: '<b>seven<e>',\n",
        "    8: '<b>eight<e>',\n",
        "    9: '<b>nine<e>'\n",
        "}\n",
        "\n",
        "def tokenize_label(value):\n",
        "    formatted_value = value.replace('<b>', ' <b> ').replace('<e>', ' <e> ')\n",
        "    tokens = []\n",
        "    for part in formatted_value.split():\n",
        "        tokens.extend([part] if part in ['<b>', '<e>'] else list(part))\n",
        "    return tokens\n",
        "\n",
        "vocab = list(set(token for value in labelDict.values() for token in tokenize_label(value)))\n",
        "vocab.sort()\n",
        "vocab_size = len(vocab)\n",
        "print(\"Sorted Vocabulary:\", vocab)\n",
        "print(\"Vocabulary Size:\", vocab_size)\n",
        "\n",
        "\n",
        "# Testing that your lookup tables are setup correctly\n",
        "assert(vocab_size == 17)\n",
        "assert(len(labelDict) == 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "hcsxQoFnoMi0"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "###################### DO NOT MODIFY THIS CELL #################################\n",
        "################################################################################\n",
        "# Some utility functions to check if your code is working as intended\n",
        "def assert_encoding(actual, expected):\n",
        "  assert(type(actual) == type(torch.tensor(0))) # Your output is not of type tensor, please ensure that your function should output tensors\n",
        "  if(not((expected.numpy() == actual.numpy()).all())):\n",
        "    print('expected: ', expected)\n",
        "    print('actual: ', actual)\n",
        "    assert((expected.numpy() == actual.numpy()).all())\n",
        "\n",
        "# Utility function to assert shape of a tensor, for debugging purpose\n",
        "def shapeChecker(x, y):\n",
        "  assert(x.shape == y.shape)\n",
        "\n",
        "# Get the index of a token in the vocab\n",
        "def get_idx(letter):\n",
        "    return [i for i, x in enumerate(vocab) if (letter == x)][0]\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "ODtMG2xbjydT"
      },
      "outputs": [],
      "source": [
        "# Function to convert a list of labels to a list of one-hot matrix\n",
        "def label_to_onehot_sequence(label):\n",
        "    # Map label -> one-hot sequence ############################################\n",
        "    # TODOüìù: complete the function converting a single label to its corresponsing one-hot\n",
        "    # in: 9 out: one-hot('<b>nine<e>')\n",
        "    ############################################################################\n",
        "    if isinstance(label, torch.Tensor):\n",
        "        label = label.item()\n",
        "    string_repr = labelDict[label]\n",
        "\n",
        "    # tokenize the string representation, respecting the special tokens\n",
        "    tokens = tokenize_label(string_repr)\n",
        "\n",
        "    # convert tokens to indices based on the vocabulary\n",
        "    indices = [vocab.index(token) for token in tokens]\n",
        "\n",
        "    # convert  to a one-hot tensor\n",
        "    one_hot_seq = torch.nn.functional.one_hot(torch.tensor(indices), num_classes=len(vocab))\n",
        "\n",
        "    return one_hot_seq\n",
        "\n",
        "assert_encoding(label_to_onehot_sequence(torch.tensor(3)),\n",
        "  torch.tensor([[\n",
        "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],   # <b>\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],   #  t\n",
        "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],   #  h\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],   #  r\n",
        "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],   #  e\n",
        "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],   #  e\n",
        "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], # <e>\n",
        "    dtype=torch.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "_azynUKYsnPH"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "###################### DO NOT MODIFY THIS CELL #################################\n",
        "################################################################################\n",
        "def batch_of_labels_to_onehot_matrix(labels):\n",
        "    # Convert labels to one-hot tensors\n",
        "    onehot_inputs = [label_to_onehot_sequence(label) for label in labels]\n",
        "\n",
        "    # Pad the length of string since, matrix operation requires fixed-size rows\n",
        "    max_len = max(len(onehot) for onehot in onehot_inputs)\n",
        "    padded_onehot = pad_sequence(onehot_inputs, batch_first=True, padding_value= 0)\n",
        "    return max_len, padded_onehot\n",
        "\n",
        "# Convert label to label onehot - used in the next to feed argmax input to RNN\n",
        "def label_to_onehot(target):\n",
        "    return nn.f.one_hot(target, num_classes=10).to(torch.float32)\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "kKUMCyjYWGin"
      },
      "outputs": [],
      "source": [
        "# To convert token indices predicted by our model back to characters and form the word\n",
        "def token_idx_to_token(input):\n",
        "\n",
        "    # Convert list of token idx to '<b>œÜ<e>' ##################################\n",
        "    # TODOüìù: complete the function to convert a list of token indices to the format '<b>œÜ<e>'\n",
        "    # For each index in the input list, get the corresponding token from vocab, to build the output word\n",
        "    # example input -> [ 0, 3, 6, 13, 2,  1] -> '<b>five<e>'\n",
        "    #                    ‚¨á ‚¨á ‚¨á   ‚¨á ‚¨á  ‚¨á\n",
        "    #                   <b> f  i   v  e  <e>\n",
        "    return ''.join(vocab[i] for i in input)\n",
        "\n",
        "assert(token_idx_to_token([0, 3,  6, 13,  2,  1]) == '<b>five<e>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv1RgBq6g11d"
      },
      "source": [
        "## 1.2 Data Exploration\n",
        "---\n",
        "1. Write code to fetch a batch from the `train_loader` and display the first 10 images along with their respective sequence of tokens which will be of the form `<b>` $\\phi$ `<e>`, where $\\phi \\in \\lbrace \\texttt{zero}, \\texttt{one}, \\texttt{two}, \\ldots, \\texttt{nine}\\rbrace$.\n",
        "\n",
        "Use `matplotlib` and Jupyter notebook's visualisation capabilities. See this [PyTorch tutorial page](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) for hints on how display images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "-P9WZJC_gyoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "042fa82b-347d-4e0d-91e1-93cb51fccd11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualise the dataset images #################################################\n",
        "# TODOüìù: Fetch a batch from the train_loader and display the first 10 images along\n",
        "#       with the label and the respective token sequence of the form <b>œÜ<e>\n",
        "################################################################################\n",
        "import matplotlib.pyplot as plt\n",
        "def visualise_images(train_loader, num_images=10):\n",
        "    # Your code goes here\n",
        "    data_iter = iter(train_loader)\n",
        "    images, labels = next(data_iter)\n",
        "\n",
        "    fig,axes = plt.subplots(nrows=1,ncols=num_images, figsize = (20, 5))\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "      if i >= num_images:\n",
        "        break\n",
        "\n",
        "      ax.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
        "      ax.set_title(labelDict[labels[i].item()])\n",
        "      ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to visualize the images along with the label\n",
        "visualise_images(train_loader)  # Assuming `train_loader` is your DataLoader object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTIS2SX4hzNu"
      },
      "source": [
        "## Training and Validation Functions\n",
        "---\n",
        "‚õîÔ∏è‚õîÔ∏è‚õîÔ∏è **Skip this cell for now, and you will have to revisit this cell 3 times, once you have defined your models in Section 2.1, 2.2, and 2.3.**\n",
        "\n",
        "Below are the `train()` and `evaluate()` procedures that you will call using your model to train your model and get accuracy on the validation set respectively. A few lines are omitted in the functions. Complete the following parts:\n",
        "\n",
        "1. Select the appropriate loss function for the tasks.\n",
        "2. Perform the forward pass of the model.\n",
        "3. Compute the loss.\n",
        "4. Zero the gradients of the parameters for no gradient aggregation.\n",
        "5. Compute gradients.\n",
        "6. Optimization step.\n",
        "\n",
        "Please go through both functions thoroughly to understand how accuracy is calculated and how input augmentation is performed before sending it to our models. This way, for other similar tasks, you can emulate similar functions in the future.\n",
        "\n",
        "**`train()`** takes input parameters - **`num_epoch`, `optimiser`, `model`, `dataloader`, and `mode`**.\n",
        "\n",
        "**`mode`** can have the following enums:\n",
        "\n",
        "- `'ENCODER'` for training/evaluating CNN classifier - Section 2.1\n",
        "- `'DECODER'` for training/evaluating the RNN model - Section 2.2\n",
        "- `'MODULAR'` for evaluating the modular approach - Section 2.3\n",
        "- `'E2E'` for training/evaluating the Sections 2.4 and 2.5\n",
        "\n",
        "`evaluate()` takes input parameters - `model`, `dataloader`, and `mode`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "QnXUEOzhx-0x"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "###################### DO NOT MODIFY THIS CELL #################################\n",
        "################################################################################\n",
        "# Utility function to print statistics for debugging as well as modifies target and output for accuracy calculation\n",
        "def trainUtility(batch_idx, epoch, output, target, padded_onehot):\n",
        "    # Printing statistics for easy debugging\n",
        "    if batch_idx == 1 or (epoch != None and epoch%500==0):\n",
        "        _, pred_idx = torch.max(output, dim=-1)\n",
        "        _, true_idx = torch.max(padded_onehot[:, 1:, :], dim=-1)\n",
        "        print('acc: ', torch.sum(pred_idx == true_idx)/(pred_idx.shape[0]*pred_idx.shape[1]))\n",
        "        print(pred_idx[0, :], true_idx[0, :])\n",
        "\n",
        "    # Converting output of size (batch_size x max_word_length-1 x vocab_size) -> ((batch_size*(max_word_length-1)) x vocab_size)\n",
        "    output =  output.view(-1, vocab_size)\n",
        "    # Converting the true labels to ((batch_size*(max_word_length-1)) x vocab_size)\n",
        "    # omitting the first character since, this is not getting predicted by the model\n",
        "    target = padded_onehot[:, 1:, :].reshape(-1, vocab_size)\n",
        "\n",
        "    return output, target\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "memn3pIvIdaN"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "###################### DO NOT MODIFY THIS CELL #################################\n",
        "################################################################################\n",
        "# We will create a custom dataset for training our RNN in part 2.2, data will be a tuple of\n",
        "# one-hot matrix for each label (batch_size x 10) and corresponding one-hot matrix of words (batch_size x max_word_length x vocab_size)\n",
        "class RnnTrainingDataset(Dataset):\n",
        "    \"\"\"Dataset to get a tuple of one-hot matrix for each label (batch_size x 10)\n",
        "       and corresponding one-hot matrix of words (batch_size x max_word_length - 1 x vocab_size)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        \"\"\"\n",
        "        self.X = label_to_onehot(torch.tensor([x for x in range(10)]))\n",
        "        _, self.Y = batch_of_labels_to_onehot_matrix(torch.tensor([x for x in range(10)]))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10 # There are only 10 words\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], self.Y[idx])\n",
        "\n",
        "rnn_dataset = RnnTrainingDataset()\n",
        "rnn_dataloader = torch.utils.data.DataLoader(rnn_dataset, batch_size=10, shuffle=True)\n",
        "rnn_testloader = torch.utils.data.DataLoader(rnn_dataset, batch_size=1, shuffle=True)\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "qGWgcXa2hyhK"
      },
      "outputs": [],
      "source": [
        "# Function which does the training for number of epochs and model and type of model passed\n",
        "def train(num_epochs, optimiser, model, dataloader=train_loader, mode='ENCODER'):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    # Select Loss ##############################################################\n",
        "    # TODOüìù: criterion = loss function to classify into K classes\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    ############################################################################\n",
        "    lr_list = []\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch_idx, (data, target) in enumerate(dataloader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "\n",
        "          if(mode == 'E2E'): # For 2.4 and 2.5 - CNN-RNN models\n",
        "            # Convert labels to one-hot tensors\n",
        "            _, padded_onehot = batch_of_labels_to_onehot_matrix(target) # Output size (batch_size x max_word_length x vocab_size)\n",
        "            padded_onehot = padded_onehot.to(device)\n",
        "\n",
        "            output = model(data, padded_onehot[:, :-1, :])\n",
        "            # Forward pass #####################################################\n",
        "            # TODOüìù: output = forward pass of your model\n",
        "            ####################################################################\n",
        "            shapeChecker(output, padded_onehot[:, 1:, :])\n",
        "\n",
        "            # Call trainUtility\n",
        "            output, target = trainUtility(batch_idx, None, output, target, padded_onehot)\n",
        "            target = target.float()\n",
        "\n",
        "\n",
        "          elif(mode == 'ENCODER'): # For 2.1 - CNN classifier\n",
        "            # Forward pass #####################################################\n",
        "            # TODOüìù: output = forward pass of your model\n",
        "            output = model(data)\n",
        "            ####################################################################\n",
        "\n",
        "          elif(mode == 'DECODER'): # For 2.2 - Overfitting RNN\n",
        "            # Convert labels to one-hot tensors\n",
        "            padded_onehot = target\n",
        "            # Forward pass #####################################################\n",
        "            # TODOüìù: output = forward pass of your model, you will not pass the\n",
        "            #                  end token <e> to your model\n",
        "            output = model(data, padded_onehot[:, :-1, :])\n",
        "            ####################################################################\n",
        "            shapeChecker(output, target[:, 1:, :])\n",
        "\n",
        "            # Call trainUtility\n",
        "            output, target = trainUtility(batch_idx, epoch, output, target, padded_onehot)\n",
        "            target = target.float()\n",
        "\n",
        "\n",
        "          # Loss computation ###################################################\n",
        "          # TODOüìù: loss = evaluate the criterion on the model output\n",
        "          loss = criterion(output, target)\n",
        "          ######################################################################\n",
        "          # Zero grad ##########################################################\n",
        "          # TODOüìù: zero grad the parameters\n",
        "          optimiser.zero_grad()\n",
        "          ######################################################################\n",
        "          # Compute gradients ##################################################\n",
        "          # TODOüìù: back-propogate loss to calculate the grad weights\n",
        "          loss.backward()\n",
        "          ######################################################################\n",
        "          # Optimisation step ##################################################\n",
        "          # TODOüìù: perform a single optimization step (weight update)\n",
        "          optimiser.step()\n",
        "          ######################################################################\n",
        "\n",
        "\n",
        "\n",
        "          if (batch_idx+1) % 100 == 0 or (mode == 'DECODER' and epoch%500 == 0):\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, batch_idx+1, len(dataloader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "wFP1MB3Lhn2T"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "###################### DO NOT MODIFY THIS CELL #################################\n",
        "################################################################################\n",
        "def evaluate(model, dataloader=test_loader, mode='ENCODER'):\n",
        "    # Never forget to change model to eval mode using eval(), this freezes the model weights for updates\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in dataloader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        if(mode == 'ENCODER'):\n",
        "          # Predicted output\n",
        "          output = model(data)\n",
        "\n",
        "          # Calculate correct prediction count\n",
        "          pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        elif(mode == 'DECODER'):\n",
        "          # Predicted output\n",
        "          output = torch.tensor(model.sample(data), device=device)\n",
        "\n",
        "          # True output\n",
        "          _, true = torch.max(target, dim=-1)\n",
        "          # Remove padding\n",
        "          true = torch.tensor(np.concatenate(([0],np.delete(true.cpu().numpy(),\n",
        "                                                            np.argwhere(true.cpu().numpy()==0)))), device=device)\n",
        "\n",
        "          # Calculate correct prediction count\n",
        "          correct += torch.sum(output == true)/output.shape[0]\n",
        "        elif(mode == 'MODULAR'):\n",
        "          # Predicted output\n",
        "          output = model.sample(data)\n",
        "\n",
        "          # True output\n",
        "          true = [labelDict[label.item()] for label in target]\n",
        "          true = torch.tensor([0] + [get_idx(c) for c in true[0][3:-3]] + [1])\n",
        "          true = torch.full(output.shape, 20) if output.shape[0] != true.shape[0] else true\n",
        "\n",
        "          # Calculate correct prediction count\n",
        "          correct += torch.sum(output == true)/output.shape[0]\n",
        "        elif(mode == 'E2E'):\n",
        "          # Predicted output\n",
        "          output = torch.tensor(model.sample(data))\n",
        "\n",
        "          # True output\n",
        "          true = [labelDict[label.item()] for label in target]\n",
        "          true = torch.tensor([0] + [get_idx(c) for c in true[0][3:-3]] + [1])\n",
        "          true = torch.full(output.shape, 20) if output.shape[0] != true.shape[0] else true\n",
        "\n",
        "          # Calculate correct prediction count\n",
        "          correct += torch.sum(output == true)/output.shape[0]\n",
        "\n",
        "    test_loss /= len(dataloader.dataset)\n",
        "    print('\\nTest set: Accuracy: {:.0f}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(dataloader.dataset),\n",
        "        100 * correct / len(dataloader.dataset)))\n",
        "\n",
        "    return 100 * correct / len(dataloader.dataset)\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c3ICvb23OMI"
      },
      "source": [
        "# 2 Model creation and training\n",
        "## 2.1 Convolutional net architecture\n",
        "---\n",
        "Follow the following steps to train a CNN classifier and calculate accuracy for your model on the test set:\n",
        "1. Create a model exactly like the architecture given in the prog4 writeup.\n",
        "2. Create a SGD optimiser. You can read about optimisers [here](https://pytorch.org/docs/stable/optim.html).\n",
        "3. Go to previous section and fill out the `train()` procedure for `mode='ENCODER'`.\n",
        "\n",
        "This part expects you to achieve an accuracy of `95%+` on the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "QHT3Zskr3Nr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a19fbea-f1cf-4bb5-f30d-cbc4987a91d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.4629\n",
            "Epoch [1/10], Step [200/469], Loss: 0.2294\n",
            "Epoch [1/10], Step [300/469], Loss: 0.2419\n",
            "Epoch [1/10], Step [400/469], Loss: 0.0401\n",
            "Epoch [2/10], Step [100/469], Loss: 0.0491\n",
            "Epoch [2/10], Step [200/469], Loss: 0.0995\n",
            "Epoch [2/10], Step [300/469], Loss: 0.0923\n",
            "Epoch [2/10], Step [400/469], Loss: 0.0892\n",
            "Epoch [3/10], Step [100/469], Loss: 0.0520\n",
            "Epoch [3/10], Step [200/469], Loss: 0.0485\n",
            "Epoch [3/10], Step [300/469], Loss: 0.0871\n",
            "Epoch [3/10], Step [400/469], Loss: 0.0563\n",
            "Epoch [4/10], Step [100/469], Loss: 0.0548\n",
            "Epoch [4/10], Step [200/469], Loss: 0.0376\n",
            "Epoch [4/10], Step [300/469], Loss: 0.1089\n",
            "Epoch [4/10], Step [400/469], Loss: 0.0773\n",
            "Epoch [5/10], Step [100/469], Loss: 0.0451\n",
            "Epoch [5/10], Step [200/469], Loss: 0.0129\n",
            "Epoch [5/10], Step [300/469], Loss: 0.0156\n",
            "Epoch [5/10], Step [400/469], Loss: 0.0685\n",
            "Epoch [6/10], Step [100/469], Loss: 0.0164\n",
            "Epoch [6/10], Step [200/469], Loss: 0.0030\n",
            "Epoch [6/10], Step [300/469], Loss: 0.0284\n",
            "Epoch [6/10], Step [400/469], Loss: 0.0134\n",
            "Epoch [7/10], Step [100/469], Loss: 0.0405\n",
            "Epoch [7/10], Step [200/469], Loss: 0.0029\n",
            "Epoch [7/10], Step [300/469], Loss: 0.0229\n",
            "Epoch [7/10], Step [400/469], Loss: 0.0931\n",
            "Epoch [8/10], Step [100/469], Loss: 0.0030\n",
            "Epoch [8/10], Step [200/469], Loss: 0.0036\n",
            "Epoch [8/10], Step [300/469], Loss: 0.0117\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0164\n",
            "Epoch [9/10], Step [100/469], Loss: 0.0124\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0090\n",
            "Epoch [9/10], Step [300/469], Loss: 0.0057\n",
            "Epoch [9/10], Step [400/469], Loss: 0.0209\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0039\n",
            "Epoch [10/10], Step [200/469], Loss: 0.0021\n",
            "Epoch [10/10], Step [300/469], Loss: 0.0616\n",
            "Epoch [10/10], Step [400/469], Loss: 0.0592\n",
            "\n",
            "Test set: Accuracy: 9890/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# options\n",
        "epochs = 10         # number of epochs to train\n",
        "lr = 0.01           # learning rate\n",
        "\n",
        "\n",
        "# Convolutional net architecture ###############################################\n",
        "# TODOüìù: cnnEncoder = cnn model - input: image(batch_size x 1 x img_sz x img_sz)\n",
        "#                                  output: (batch_size, 84)\n",
        "# TODOüìù: linearClassifier = linear classifier - input: (batch_size, 84)\n",
        "#                                                output: (batch_size, 10)\n",
        "# Define the CNN Encoder\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 120, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(120 * 3 * 3, 84),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "cnnEncoder = CNNEncoder()\n",
        "linearClassifier = LinearClassifier()\n",
        "\n",
        "################################################################################\n",
        "# Creating Optimiser ###########################################################\n",
        "# TODOüìù: enc_optimiser = create a SGD optimiser for the cnnClassifier\n",
        "# TODOüìù: Fill out the train() procedure for mode='ENCODER' in the previous section\n",
        "################################################################################\n",
        "\n",
        "cnnClassifier = nn.Sequential(cnnEncoder, linearClassifier)\n",
        "enc_optimiser = enc_optimiser = optim.SGD(cnnClassifier.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "train(epochs, enc_optimiser, cnnClassifier, mode='ENCODER')\n",
        "acc = evaluate(cnnClassifier, test_loader, mode='ENCODER')\n",
        "\n",
        "assert(acc > 95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftoGfiIuFMh_"
      },
      "source": [
        "## 2.2 Recurrent net overfitting\n",
        "---\n",
        "We can define models in two ways, either using `nn.Sequential()` to create a network where PyTorch takes care of `forward()`, or we can create a `class` inhereted from `nn.Module` and define our custom `forward()` and other utility functions. For this section, we will use the latter approach.\n",
        "Follow the next steps to train your RNN model and calculate the accuracy:\n",
        "1. Create a model by completing the class methods where asked.\n",
        "2. Create an optimiser.\n",
        "3. Go to previous section and fill out the `train()` procedure for `mode='DECODER'`.\n",
        "\n",
        "This part expects you to achieve an accuracy of `10/10` on the training set, that is we completely memorise the training data points.\n",
        "\n",
        "\n",
        "You can use the following documentations for reference on [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) and [`nn.LSTM`](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "5Y6hyYp7FG7B"
      },
      "outputs": [],
      "source": [
        "# 1. RNN model for learning sequence of letters\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, vocab_size, num_layers):\n",
        "        super().__init__()\n",
        "        # Create LSTM and Linear objects #######################################\n",
        "        # TODOüìù: self.lstm = LSTM object using input_size, hidden_size and num_layers,\n",
        "        #                     set the batch_first option to True\n",
        "        # TODOüìù: self.fc = Linear layer to convert to get final output with size\n",
        "        #                   (batch_size x vocab_size)\n",
        "        ########################################################################\n",
        "        self.lstm = nn.LSTM(input_size + vocab_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # input is batch of one-hot labels of shape (batch_size x 10)\n",
        "        # target is one-hot of sequence of tokens without the last token and is of\n",
        "        # shape (batch_size x max_word_length-1 x vocab_size)\n",
        "\n",
        "        # Setup ################################################################\n",
        "        # TODOüìù: Using target assign the three variables with the corresponding values of\n",
        "        #         batch_size, max_word_length, and vocab_size\n",
        "        ########################################################################\n",
        "        batch_size, max_word_length, vocab_size = target.size()\n",
        "        max_word_length += 1\n",
        "\n",
        "        # Feed-forward behaviour of the model ##################################\n",
        "        # In order to pass two inputs to our LSTM object, we need to concat input and target,\n",
        "        # we will need to change (batch_size x 10) input matrix -> (batch_size x max_word_length-1 x 10)\n",
        "        # TODOüìù: replicated_input = repeat the one-hot input (max_word_length-1)\n",
        "        #         times on 2nd dimension -> (batch_size x max_word_length-1 x 10)\n",
        "        # TODOüìù: rnn_input = concat the target with the replicated_input ->\n",
        "        #         (batch_size x max_word_length-1 x vocab_size+10)\n",
        "\n",
        "\n",
        "        # TODOüìù: out = write the feed-forward behaviour of the network\n",
        "        ########################################################################\n",
        "        replicated_input = input.unsqueeze(1).repeat(1, max_word_length-1, 1)\n",
        "        rnn_input = torch.cat((replicated_input, target), dim=-1)\n",
        "\n",
        "        shapeChecker(rnn_input, torch.zeros((batch_size, max_word_length-1, vocab_size+10)))\n",
        "        lstm_out, _ = self.lstm(rnn_input)\n",
        "        out = self.fc(lstm_out)\n",
        "\n",
        "        shapeChecker(out, target)\n",
        "        return out\n",
        "\n",
        "    # Utility function to create next input_rnn using the current token and one-hot label(input)\n",
        "    def create_concatenated_rnn_input(self, token_idx, input_digit):\n",
        "        # input is single one-hot label of shape (1 x 10)\n",
        "        # token_idx is a token index\n",
        "        # Create rnn_input of (1 x 1 x vocab_size+10) ##########################\n",
        "        # TODOüìù: rnn_input = matrix of (1 x 1 x vocab_size+10), which is the concatenation\n",
        "        #         of the input and the one-hot vector corresponding to the token idx\n",
        "\n",
        "        ########################################################################\n",
        "        token_one_hot = nn.functional.one_hot(torch.tensor(token_idx), num_classes=vocab_size).float().view(-1).to(device)\n",
        "        rnn_input = torch.cat([input_digit.unsqueeze(0), token_one_hot.unsqueeze(0).unsqueeze(1)], dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "        shapeChecker(torch.zeros((1, 1, vocab_size+10)), rnn_input)\n",
        "        return rnn_input\n",
        "\n",
        "    # This function samples next token given the <b> token until the <e> token\n",
        "    def sample(self, input):\n",
        "        # input is single one-hot label of shape (1 x 10)\n",
        "        output = [get_idx('<b>')] # Output is sequence of token indices, and here we intialise with <b>\n",
        "        rnn_input = self.create_concatenated_rnn_input(get_idx('<b>'), input) # create first input\n",
        "        loopRun = 0\n",
        "        h = None\n",
        "        c = None\n",
        "        while True and loopRun < 50:  # Breaking condition : predicted idx == <e>\n",
        "            # the loopRun < 50 condition prevent infinite looping\n",
        "\n",
        "            # Feed-forward behaviour ###########################################\n",
        "            # TODOüìù: out = write the feed-forward behaviour\n",
        "            # Here, since we are working with single token at a time,\n",
        "            # you need to convert out: (1 x 1 x vocab_size) -> (1 x vocab_size)\n",
        "            ####################################################################\n",
        "            if h == None or c == None:\n",
        "              out, (h,c) = self.lstm(rnn_input)\n",
        "            else:\n",
        "              out, (h,c) = self.lstm(rnn_input, (h,c))\n",
        "            out = self.fc(out).squeeze(0)\n",
        "\n",
        "            shapeChecker(out, torch.zeros((1, vocab_size)))\n",
        "\n",
        "            _, pred_idx = torch.max(out, dim=-1)\n",
        "\n",
        "            output.append(pred_idx.cpu().numpy()[0].item())\n",
        "            # Breaking condition ###############################################\n",
        "            # TODOüìù: add breaking condition on predicted token == '<e>'\n",
        "            ####################################################################\n",
        "            if pred_idx.item() == get_idx('<e>'):\n",
        "                break\n",
        "\n",
        "            # Prepare next rnn input ###########################################\n",
        "            # TODOüìù: rnn_input = overwrite the rnn_input using the current\n",
        "            #         predicted token for the next iteration\n",
        "            ####################################################################\n",
        "            rnn_input = self.create_concatenated_rnn_input(pred_idx.item(), input)\n",
        "            loopRun+=1\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "V8psC0whkaKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4f43e0-1971-482f-a3c1-cd4ec8cdfc9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  tensor(0.0167)\n",
            "tensor([15, 15, 15, 15, 15, 15]) tensor([8, 7, 2, 1, 0, 0])\n",
            "Epoch [1/5000], Step [1/1], Loss: 2.3648\n",
            "acc:  tensor(0.2167)\n",
            "tensor([2, 2, 1, 1, 1, 1]) tensor([8, 7, 2, 1, 0, 0])\n",
            "Epoch [501/5000], Step [1/1], Loss: 1.8233\n",
            "acc:  tensor(0.4667)\n",
            "tensor([2, 2, 2, 2, 2, 1]) tensor([10,  2, 13,  2,  7,  1])\n",
            "Epoch [1001/5000], Step [1/1], Loss: 1.1028\n",
            "acc:  tensor(0.7500)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [1501/5000], Step [1/1], Loss: 0.5593\n",
            "acc:  tensor(0.8333)\n",
            "tensor([11, 14,  8,  1,  1,  1]) tensor([11, 14,  8,  1,  0,  0])\n",
            "Epoch [2001/5000], Step [1/1], Loss: 0.2549\n",
            "acc:  tensor(0.8333)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [2501/5000], Step [1/1], Loss: 0.1201\n",
            "acc:  tensor(0.8333)\n",
            "tensor([11, 14,  8,  1,  1,  1]) tensor([11, 14,  8,  1,  0,  0])\n",
            "Epoch [3001/5000], Step [1/1], Loss: 0.0662\n",
            "acc:  tensor(0.8333)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [3501/5000], Step [1/1], Loss: 0.0425\n",
            "acc:  tensor(0.8333)\n",
            "tensor([ 3,  8, 12,  9,  1,  1]) tensor([ 3,  8, 12,  9,  1,  0])\n",
            "Epoch [4001/5000], Step [1/1], Loss: 0.0303\n",
            "acc:  tensor(0.8333)\n",
            "tensor([16,  2,  9,  8,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [4501/5000], Step [1/1], Loss: 0.0232\n",
            "\n",
            "Test set: Accuracy: 10/10 (100%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Create an optimiser\n",
        "# options\n",
        "epochs = 5000         # number of epochs to train\n",
        "lr = 0.1             # learning rate - TODOüìù: set an appropriate lr\n",
        "hidden_size = 32    # hidden size for rnn - TODOüìù: set from 8, 16, 32, 64 - use the smallest one for which your model works\n",
        "embed_size = 10       # input is onehot labels\n",
        "num_layer = 1         # layers of rnn\n",
        "\n",
        "# Recurrent net overfitting ####################################################\n",
        "# TODOüìù: rnnModel = DecoderRNN() model - input: one-hot label output: one-hot matrix of words\n",
        "# TODOüìù: dec_optimiser = create a SGD optimiser object\n",
        "################################################################################\n",
        "rnnModel = DecoderRNN(embed_size, hidden_size, vocab_size, num_layer)\n",
        "dec_optimiser = optim.SGD(rnnModel.parameters(), lr=lr)\n",
        "\n",
        "train(epochs, dec_optimiser, rnnModel, mode='DECODER', dataloader=rnn_dataloader)\n",
        "acc = evaluate(rnnModel, rnn_testloader, mode='DECODER')\n",
        "\n",
        "assert(acc == 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmSqHzirl2Ny"
      },
      "source": [
        "## 2.3 Modular approach\n",
        "---\n",
        "In this section, we will combine the previously trained CNN and RNN to convert an input image to a sequence of tokens.\n",
        "Here, since both models are pre-trained we just evaluate the performance of this combined model.\n",
        "\n",
        "Create a class `CombinationModel`: with a `sample()` method which takes an image as input and outputs token indices for each predicted letter of size `(batch_size x word_length)`. You can call the sample method of `DecoderRNN` for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "JZEykWBJoXdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808ec01e-8be5-47da-f2c3-78e618285816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Accuracy: 9901/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class CombinationModel(nn.Module):\n",
        "    def __init__(self, cnn, rnn):\n",
        "        super(CombinationModel, self).__init__()\n",
        "        self.cnn = cnn\n",
        "        self.rnn = rnn\n",
        "\n",
        "    def sample(self, image):\n",
        "        features = self.cnn(image)\n",
        "        stacked_features = torch.stack(tuple(features), dim=0)\n",
        "        argmax_indices = torch.argmax(stacked_features, dim=-1)\n",
        "        one_hot_input = nn.f.one_hot(argmax_indices, num_classes=stacked_features[0].shape[-1]).float()\n",
        "        token_indices = self.rnn.sample(one_hot_input)\n",
        "        output = torch.tensor(token_indices)\n",
        "        return output\n",
        "\n",
        "# Modular approach #############################################################\n",
        "# TODOüìù: create a class as mentioned before\n",
        "# TODOüìù: combinationModel = instantiate your created class\n",
        "################################################################################\n",
        "combinationModel = CombinationModel(cnnClassifier, rnnModel)\n",
        "acc = evaluate(combinationModel, test_loader, mode='MODULAR')\n",
        "\n",
        "assert(acc > 95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVh746TQo97u"
      },
      "source": [
        "## 2.4 Transfer learning\n",
        "---\n",
        "\n",
        "In this section, we will use the `cnnEncoder` that we trained in section 2.1 to get the image embeddings which we will use instead of the one-hot label we used in section 2.2. Complete the following methods using section 2.2 as reference:\n",
        "1. Create a `DecoderRNN2` model;\n",
        "2. Create a `DigitDecoder` model (you may want to look at the methods of `DecoderRNN` from section 2.2);\n",
        "3. Instantiate an object of `DigitDecoder`;\n",
        "4. Create a SGD optimiser for the `DecoderRNN2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "aNs_xKALtnEX"
      },
      "outputs": [],
      "source": [
        "# 1. RNN model for learning sequence of letters\n",
        "class DecoderRNN2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, vocab_size, num_layers):\n",
        "        # Initialisation of the class ##########################################\n",
        "        # TODOüìù: create LSTM and linear layer\n",
        "        ########################################################################\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Concatenated vector of image embedding and one-hot of the whole\n",
        "        # sequence of tokens without the last one of size (batch_size x max_word_length-1 x vocab_size+embed_size)\n",
        "        # Feed-forward behaviour ###############################################\n",
        "        # TODOüìù: write the feed-forward behaviour of the model\n",
        "        ########################################################################\n",
        "        out, hidden = self.lstm(input)\n",
        "        output = self.fc(out)\n",
        "        return output, hidden\n",
        "\n",
        "    def single_forward(self, input, hidden):\n",
        "        # This function is called by DigitDecoder to output a single token given\n",
        "        # the previous token along with the image embedding and the corresponding hidden tensor\n",
        "        # Prediction behaviour #################################################\n",
        "        # TODOüìù: do a forward pass of the model\n",
        "        # TODOüìù: return output and new hidden\n",
        "        ########################################################################\n",
        "        out, hidden = self.lstm(input, hidden)\n",
        "        output = self.fc(out.squeeze(1))\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "dKnUTAFg_hix"
      },
      "outputs": [],
      "source": [
        "# 2. Model to predict next words given the image\n",
        "class DigitDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        # Initialise the model #################################################\n",
        "        # TODOüìù: self.encoder = use the cnnEncoder\n",
        "        # TODOüìù: self.decoder = instantiation of DecoderRNN2\n",
        "        ########################################################################\n",
        "        self.encoder = cnnEncoder\n",
        "        self.decoder = DecoderRNN2(input_size, hidden_size, num_classes, num_layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Feed-forward behaviour of the model ##################################\n",
        "        # TODOüìù: try to emulate forward() from section 2.2\n",
        "        # Some extra work is needed: calculate image embedding using\n",
        "        # the self.encoder\n",
        "        embedding = self.encoder.forward(x)\n",
        "        replicated_input = embedding.unsqueeze(1).repeat(1, y.shape[1], 1)\n",
        "        input = torch.cat((replicated_input, y), dim=2)\n",
        "        output, _ = self.decoder(input)\n",
        "        return output\n",
        "\n",
        "    def sample(self, x):\n",
        "        # Sampling the output string one token at a time #######################\n",
        "        # TODOüìù: try to emulate sample() method from section 2.2\n",
        "        # Some extra work is needed: calculate image embedding using\n",
        "        # the self.encoder\n",
        "        ########################################################################\n",
        "        output = [get_idx('<b>')]\n",
        "        embedding = self.encoder.forward(x).to(device)\n",
        "        token_one_hot = torch.zeros(1, vocab_size, device=device)\n",
        "        token_one_hot[0, output[0]] = 1\n",
        "        input = torch.cat((embedding, token_one_hot), dim=1).unsqueeze(1)\n",
        "        loopRun = 0\n",
        "\n",
        "        h = None\n",
        "        c = None\n",
        "        while True and loopRun < 50:\n",
        "            out, h = self.decoder.single_forward(input, h)\n",
        "            token = out.argmax(dim=1)\n",
        "            output.append(token)\n",
        "\n",
        "            if token == get_idx('<e>'):\n",
        "                break\n",
        "\n",
        "            token_one_hot = torch.zeros(1, vocab_size, device=device)\n",
        "            token_one_hot[0, output[0]] = 1\n",
        "            input = torch.cat((embedding, token_one_hot), dim=1).unsqueeze(1)\n",
        "            loopRun += 1\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLe3qH_-xlLS",
        "outputId": "b774af54-7269-47c2-e969-2b40a8c02b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  tensor(0.0130)\n",
            "tensor([16, 16,  3,  3,  3,  3]) tensor([11, 14,  8,  1,  0,  0])\n",
            "Epoch [1/10], Step [100/469], Loss: 1.9801\n",
            "Epoch [1/10], Step [200/469], Loss: 1.8433\n",
            "Epoch [1/10], Step [300/469], Loss: 1.5849\n",
            "Epoch [1/10], Step [400/469], Loss: 1.3689\n",
            "acc:  tensor(0.4349)\n",
            "tensor([7, 2, 2, 2, 2, 1]) tensor([10,  2, 13,  2,  7,  1])\n",
            "Epoch [2/10], Step [100/469], Loss: 1.0202\n",
            "Epoch [2/10], Step [200/469], Loss: 0.7859\n",
            "Epoch [2/10], Step [300/469], Loss: 0.6261\n",
            "Epoch [2/10], Step [400/469], Loss: 0.5031\n",
            "acc:  tensor(0.7878)\n",
            "tensor([8, 7, 2, 1, 1, 1]) tensor([8, 7, 2, 1, 0, 0])\n",
            "Epoch [3/10], Step [100/469], Loss: 0.3707\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3019\n",
            "Epoch [3/10], Step [300/469], Loss: 0.2709\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2018\n",
            "acc:  tensor(0.8542)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [4/10], Step [100/469], Loss: 0.1555\n",
            "Epoch [4/10], Step [200/469], Loss: 0.1007\n",
            "Epoch [4/10], Step [300/469], Loss: 0.1506\n",
            "Epoch [4/10], Step [400/469], Loss: 0.0967\n",
            "acc:  tensor(0.8411)\n",
            "tensor([7, 6, 7, 2, 1, 1]) tensor([7, 6, 7, 2, 1, 0])\n",
            "Epoch [5/10], Step [100/469], Loss: 0.0917\n",
            "Epoch [5/10], Step [200/469], Loss: 0.0668\n",
            "Epoch [5/10], Step [300/469], Loss: 0.0505\n",
            "Epoch [5/10], Step [400/469], Loss: 0.0515\n",
            "acc:  tensor(0.8216)\n",
            "tensor([7, 6, 7, 2, 1, 1]) tensor([7, 6, 7, 2, 1, 0])\n",
            "Epoch [6/10], Step [100/469], Loss: 0.0413\n",
            "Epoch [6/10], Step [200/469], Loss: 0.0975\n",
            "Epoch [6/10], Step [300/469], Loss: 0.0314\n",
            "Epoch [6/10], Step [400/469], Loss: 0.0510\n",
            "acc:  tensor(0.8229)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [7/10], Step [100/469], Loss: 0.0236\n",
            "Epoch [7/10], Step [200/469], Loss: 0.0620\n",
            "Epoch [7/10], Step [300/469], Loss: 0.0398\n",
            "Epoch [7/10], Step [400/469], Loss: 0.0385\n",
            "acc:  tensor(0.8346)\n",
            "tensor([ 2,  6,  4,  5, 11,  1]) tensor([ 2,  6,  4,  5, 11,  1])\n",
            "Epoch [8/10], Step [100/469], Loss: 0.0229\n",
            "Epoch [8/10], Step [200/469], Loss: 0.0173\n",
            "Epoch [8/10], Step [300/469], Loss: 0.0282\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0262\n",
            "acc:  tensor(0.8385)\n",
            "tensor([ 3,  8, 12,  9,  1,  1]) tensor([ 3,  8, 12,  9,  1,  0])\n",
            "Epoch [9/10], Step [100/469], Loss: 0.0259\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0213\n",
            "Epoch [9/10], Step [300/469], Loss: 0.0250\n",
            "Epoch [9/10], Step [400/469], Loss: 0.0418\n",
            "acc:  tensor(0.8333)\n",
            "tensor([16,  2,  9,  8,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0216\n",
            "Epoch [10/10], Step [200/469], Loss: 0.0205\n",
            "Epoch [10/10], Step [300/469], Loss: 0.0573\n",
            "Epoch [10/10], Step [400/469], Loss: 0.0189\n",
            "\n",
            "Test set: Accuracy: 9871/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. and 4. model instantiation and optimiser creation\n",
        "epochs = 10           # number of epochs to train\n",
        "lr = 0.1              # learning rate\n",
        "hidden_size = 64    # hidden size for rnn - set from 8, 16, 32, 64 - use the smallest one for which your model works\n",
        "num_layer = 2         # layers of rnn\n",
        "embed_size = 84\n",
        "input_size = 101\n",
        "\n",
        "# Transfer learning ############################################################\n",
        "# TODOüìù: tranferLearningModel = create an object of DigitDecoder\n",
        "# TODOüìù: tra_optimiser = create a SGD optimiser object using just the DecoderRNN2 parameters\n",
        "################################################################################\n",
        "transferLearningModel = DigitDecoder(input_size, hidden_size, num_layer, vocab_size)\n",
        "tra_optimiser = optim.SGD(transferLearningModel.decoder.parameters(), lr=lr)\n",
        "\n",
        "train(epochs, tra_optimiser, transferLearningModel, mode='E2E')\n",
        "acc = evaluate(transferLearningModel, test_loader, mode='E2E')\n",
        "\n",
        "assert(acc > 95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k94y4Bb-yhL7"
      },
      "source": [
        "## 2.5 End-to-end training\n",
        "---\n",
        "Finally, we will remove all the restrictions and train the `DigitDecoder` on both CNN as well as `DecoderRNN2` parameters.\n",
        "\n",
        "Follow the same steps as sec 2.4.\n",
        "1. Create a new class `DigitDecoder2` similar to `DigitDecoder` except here instead of using the pre-trained `cnnEncoder`, instantiate a new encoder with the same hyper-parameter.\n",
        "1. Instantiate an object of `DigitDecoder2`.\n",
        "2. Create an optimiser object using the `DigitDecoder2` weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtbsQ6qMygTb",
        "outputId": "0d87e276-f09e-4b4c-c106-5df27e24476f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  tensor(0.0221)\n",
            "tensor([12, 12, 12, 12, 12, 12]) tensor([11, 14,  8,  1,  0,  0])\n",
            "Epoch [1/10], Step [100/469], Loss: 2.1225\n",
            "Epoch [1/10], Step [200/469], Loss: 2.0380\n",
            "Epoch [1/10], Step [300/469], Loss: 1.8546\n",
            "Epoch [1/10], Step [400/469], Loss: 1.8654\n",
            "acc:  tensor(0.2839)\n",
            "tensor([6, 6, 2, 2, 1, 1]) tensor([11, 14,  8,  1,  0,  0])\n",
            "Epoch [2/10], Step [100/469], Loss: 1.6768\n",
            "Epoch [2/10], Step [200/469], Loss: 1.6434\n",
            "Epoch [2/10], Step [300/469], Loss: 1.6442\n",
            "Epoch [2/10], Step [400/469], Loss: 1.4833\n",
            "acc:  tensor(0.3568)\n",
            "tensor([10,  6,  9,  2,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [3/10], Step [100/469], Loss: 1.2135\n",
            "Epoch [3/10], Step [200/469], Loss: 1.1958\n",
            "Epoch [3/10], Step [300/469], Loss: 0.9774\n",
            "Epoch [3/10], Step [400/469], Loss: 0.8001\n",
            "acc:  tensor(0.5312)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [4/10], Step [100/469], Loss: 0.5077\n",
            "Epoch [4/10], Step [200/469], Loss: 0.3922\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2954\n",
            "Epoch [4/10], Step [400/469], Loss: 0.3703\n",
            "acc:  tensor(0.8138)\n",
            "tensor([16,  2,  9,  8,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [5/10], Step [100/469], Loss: 0.2104\n",
            "Epoch [5/10], Step [200/469], Loss: 0.1577\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1337\n",
            "Epoch [5/10], Step [400/469], Loss: 0.1657\n",
            "acc:  tensor(0.8216)\n",
            "tensor([10,  2, 13,  2,  7,  1]) tensor([10,  2, 13,  2,  7,  1])\n",
            "Epoch [6/10], Step [100/469], Loss: 0.0616\n",
            "Epoch [6/10], Step [200/469], Loss: 0.0951\n",
            "Epoch [6/10], Step [300/469], Loss: 0.0711\n",
            "Epoch [6/10], Step [400/469], Loss: 0.0443\n",
            "acc:  tensor(0.7865)\n",
            "tensor([ 3,  8, 12,  9,  1,  1]) tensor([ 3,  8, 12,  9,  1,  0])\n",
            "Epoch [7/10], Step [100/469], Loss: 0.0661\n",
            "Epoch [7/10], Step [200/469], Loss: 0.0416\n",
            "Epoch [7/10], Step [300/469], Loss: 0.0685\n",
            "Epoch [7/10], Step [400/469], Loss: 0.0496\n",
            "acc:  tensor(0.8164)\n",
            "tensor([16,  2,  9,  8,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [8/10], Step [100/469], Loss: 0.0287\n",
            "Epoch [8/10], Step [200/469], Loss: 0.0683\n",
            "Epoch [8/10], Step [300/469], Loss: 0.1074\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0267\n",
            "acc:  tensor(0.8372)\n",
            "tensor([16,  2,  9,  8,  1,  1]) tensor([16,  2,  9,  8,  1,  0])\n",
            "Epoch [9/10], Step [100/469], Loss: 0.0204\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0219\n",
            "Epoch [9/10], Step [300/469], Loss: 0.0495\n",
            "Epoch [9/10], Step [400/469], Loss: 0.0276\n",
            "acc:  tensor(0.8034)\n",
            "tensor([10,  6, 15,  1,  1,  1]) tensor([10,  6, 15,  1,  0,  0])\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0608\n",
            "Epoch [10/10], Step [200/469], Loss: 0.0262\n",
            "Epoch [10/10], Step [300/469], Loss: 0.0362\n",
            "Epoch [10/10], Step [400/469], Loss: 0.0285\n",
            "\n",
            "Test set: Accuracy: 9846/10000 (98%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DigitDecoder2(nn.Module):\n",
        "  # Fill out the class methods #################################################\n",
        "  # TODOüìù: Create a new DigitDecoder2 class, with the difference in self.encoder,\n",
        "  #         where you need to a new cnn encoder with same hyper-parameter as in\n",
        "  #         section 2.1 without the last layer.\n",
        "  ##############################################################################\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        # Initialise the model #################################################\n",
        "        # TODOüìù: self.encoder = use the cnnEncoder\n",
        "        # TODOüìù: self.decoder = instantiation of DecoderRNN2\n",
        "        ########################################################################\n",
        "        self.encoder = CNNEncoder()\n",
        "        self.decoder = DecoderRNN2(input_size, hidden_size, num_classes, num_layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Feed-forward behaviour of the model ##################################\n",
        "        # TODOüìù: try to emulate forward() from section 2.2\n",
        "        # Some extra work is needed: calculate image embedding using\n",
        "        # the self.encoder\n",
        "        embedding = self.encoder.forward(x)\n",
        "        replicated_input = embedding.unsqueeze(1).repeat(1, y.shape[1], 1)\n",
        "        input = torch.cat((replicated_input, y), dim=2)\n",
        "        output, _ = self.decoder(input)\n",
        "        return output\n",
        "\n",
        "    def sample(self, x):\n",
        "        # Sampling the output string one token at a time #######################\n",
        "        # TODOüìù: try to emulate sample() method from section 2.2\n",
        "        # Some extra work is needed: calculate image embedding using\n",
        "        # the self.encoder\n",
        "        ########################################################################\n",
        "        output = [get_idx('<b>')]\n",
        "        embedding = self.encoder.forward(x)\n",
        "\n",
        "        token_one_hot = torch.zeros(1, vocab_size, device=device)\n",
        "        token_one_hot[0, output[0]] = 1\n",
        "        input = torch.cat((embedding.to(device), token_one_hot), dim=1).unsqueeze(1)\n",
        "\n",
        "        loopRun = 0\n",
        "\n",
        "        h = None\n",
        "        c = None\n",
        "        while True and loopRun < 50:\n",
        "            out, h = self.decoder.single_forward(input, h)\n",
        "            cur_token = out.argmax(dim=1)\n",
        "            output.append(cur_token)\n",
        "\n",
        "            if cur_token == get_idx('<e>'):\n",
        "                break\n",
        "\n",
        "            token_one_hot = torch.zeros(1, vocab_size, device=device)\n",
        "            token_one_hot[0, output[0]] = 1\n",
        "\n",
        "            input = torch.cat((embedding, token_one_hot), dim=1).unsqueeze(1)\n",
        "\n",
        "            loopRun += 1\n",
        "        return output\n",
        "\n",
        "# options\n",
        "epochs = 10       # number of epochs to train - TODOüìù: set number of epochs\n",
        "lr = 0.1           # learning rate - TODOüìù: set appropriate lr\n",
        "hidden_size = 64  # hidden size for rnn - TODOüìù: you may use the last lr\n",
        "num_layer = 2    # layers of rnn - TODOüìù: decide on number of layers to have in the rnn\n",
        "\n",
        "\n",
        "# End-to-end training ##########################################################\n",
        "# TODOüìù: e2eModel = create an object of DigitDetector\n",
        "# TODOüìù: e2eOptimiser = create an optimiser object using DigitDetector parameters\n",
        "################################################################################\n",
        "e2eModel = DigitDecoder2(input_size, hidden_size, num_layer, vocab_size)\n",
        "e2eOptimiser = torch.optim.SGD(e2eModel.parameters(), lr=lr)\n",
        "\n",
        "train(epochs, e2eOptimiser, e2eModel, mode='E2E')\n",
        "acc = evaluate(e2eModel, test_loader, mode='E2E')\n",
        "\n",
        "assert(acc > 95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD8pta-Tzkm0"
      },
      "source": [
        "# 3 Inference\n",
        "## 3.1 Evaluation and models comparison\n",
        "---\n",
        "Now that we are done with training our models and hopefully have got near perfect accuracies on all our tasks, its time to see the predictions of our model.\n",
        "1. Complete the function `infer()` that displays any 10 images along with their predicted texts. We will call the function for the following models:\n",
        "    1. `combinationModel`\n",
        "    2. `tranferLearningModel`\n",
        "    3. `e2eModel`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "08xib6gw2s9a",
        "outputId": "a594e6f5-ab7e-4f91-c1e9-6e68b304dfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CombinationModel output: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TranferLearningModel output: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2eModel output: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def infer(model):\n",
        "    p = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Collect predictions for a limited number of images\n",
        "    with torch.no_grad():\n",
        "        for c, (images, _) in zip(range(10), test_loader):\n",
        "            images = images.to(device)\n",
        "            outputs = model.sample(images)\n",
        "            text = ''.join([vocab[item] for item in outputs])\n",
        "            p.append((images[0], text))\n",
        "\n",
        "    # Create a figure to display predictions\n",
        "    figure, ax = plt.subplots(nrows=1, ncols=len(p), figsize=(15, 10))\n",
        "    #figure.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "\n",
        "    # Display each image and its corresponding text\n",
        "    for i, (image, text) in enumerate(p):\n",
        "        image = image.cpu()\n",
        "        ax[i].imshow(image.squeeze(), cmap='gray')\n",
        "        ax[i].set_title(text)\n",
        "        ax[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Evaluation and models comparison #############################################\n",
        "# TODOüìù: Complete the Infer(.) function\n",
        "################################################################################\n",
        "\n",
        "print('CombinationModel output: ')\n",
        "infer(combinationModel)\n",
        "print('TranferLearningModel output: ')\n",
        "infer(transferLearningModel)\n",
        "print('E2eModel output: ')\n",
        "infer(e2eModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEPfnRFi0wRM"
      },
      "source": [
        "## Conclusion\n",
        "Congratulations!!! You just trained an image caption generator. Even though the problem on which we trained our model were simple MNIST images, the concepts and methods we learnt can be extended to train for harder datasets like [Flicker8k_Dataset](https://www.kaggle.com/datasets/adityajn105/flickr8k) or [Coco_Dataset](https://cocodataset.org/#home) as well.\n",
        "\n",
        "I would highly recomment that you try with these datasets and see how well different approaches are performing, you may need to tweak with more complex and deeper models in order to get satisfactory accuracy."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}